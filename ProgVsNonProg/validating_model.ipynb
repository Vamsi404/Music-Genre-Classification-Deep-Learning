{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4pjvLsbp7FdA","executionInfo":{"status":"ok","timestamp":1714707600986,"user_tz":240,"elapsed":18063,"user":{"displayName":"Vamsi Manda","userId":"01809937866176487479"}},"outputId":"25c1f69d-5533-4839-c8f2-5c1481184ce7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import csv\n","import sys\n","import math\n","import cv2\n","import scipy\n","import pickle\n","import librosa\n","import matplotlib\n","import numpy as np\n","import librosa.display\n","import IPython.display as ipd\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import keras\n","from keras import layers\n","from keras import models\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D,Conv1D, Flatten,Dropout,MaxPooling2D\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.layers import LSTM\n","from keras.layers import Dense\n","from keras.optimizers import Adam\n","from sklearn.model_selection import KFold\n","import tensorflow as tf\n","from tensorflow.keras.optimizers.legacy import SGD\n","\n","# split data into test and train\n","def split_data_test_train(prog,nonprog) :\n","    ind1 = math.floor(len(nonprog)/3)\n","    ind2 = math.floor(len(prog)/3)\n","    x_train1 = nonprog[0:ind1]\n","    y_train1 = np.ones((ind1,1 ))\n","    x_test1 = nonprog[ind1:]\n","    y_test1 = np.ones((len(nonprog) - ind1,1) )\n","    print(len(x_test1) )\n","    print(len(y_test1) )\n","\n","    x_train2 = prog[0:ind2]\n","    y_train2 = np.zeros( ( ind2,1 ))\n","    x_test2 = prog[ind2:]\n","    y_test2 = np.zeros( (len(prog) - ind2,1 ))\n","\n","    print(len(x_test2) )\n","    print(len(y_test2) )\n","\n","\n","    x_test = x_train1 + x_train2\n","    x_train = x_test1 + x_test2\n","    y_test = np.concatenate((y_train1, y_train2), axis=0)\n","    y_train = np.concatenate((y_test1, y_test2), axis=0)\n","    print(\"x_train \",len(x_train)  )\n","    print(\"x-test \",len(x_test)  )\n","    print(\"y_train \",len(y_train)  )\n","    print(\"y_test \",len(y_test)  )\n","    return [x_train,x_test,y_train,y_test]\n","\n","\n","# Get train data from csv file\n","x_train = []\n","y_train = []\n","prog = []\n","\n","nonprog = []\n","\n","data = pd.read_csv('/content/drive/MyDrive/Music-Genre-Classification-master-20240427T160246Z-001/Music-Genre-Classification-master/training_features_10_secs.csv')\n","# print(data.head())\n","data = data.drop(['filename'],axis=1)\n","data = np.asarray(data)\n","X = data[:,6:]\n","y = data[:,0]\n","y[y==\"prog\"] = 0\n","y[y==\"non_prog\"] = 1\n","\n","x_train, x_test, y_train, y_test = train_test_split( X, y, test_size=0.5, random_state=42)\n","\n","X = np.reshape(X, (X.shape[0],1,X.shape[1]))\n","\n","\n","print(\"X_train shape \",x_train.shape)\n","print(\"y_train shape \",y_train.shape)\n","print(x_train)\n","print(y_train)\n","print(\"X_test shape \",x_test.shape)\n","print(\"y_test shape \",y_test.shape)\n","# print(x_test)\n","# print(y_test)\n","y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n","\n","# y = to_categorical(y)\n","\n","# Build model using LSTM\n","x_train = tf.convert_to_tensor(x_train, dtype=tf.float32)  # Example: Convert to float32\n","y_train = tf.convert_to_tensor(y_train, dtype=tf.int32)    # Example: Convert to int32\n","x_test = tf.convert_to_tensor(x_test, dtype=tf.float32)  # Example: Convert to float32\n","y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)    # Example: Convert to int32\n","x_train = np.expand_dims(x_train, axis=1)\n","x_test = np.expand_dims(x_test, axis=1)\n","input_shape = (1,X.shape[2])\n","kfold = KFold(n_splits=3, shuffle=True, random_state=45)\n","cvscores = []\n","batch_size = 35\n","nb_epochs = 100\n","opt = tf.keras.optimizers.legacy.Adam()\n","\n","count = 1\n","for train, test in kfold.split(X, y):\n","  # Create model\n","    model = Sequential()\n","    model.add(LSTM(units=64, dropout=0.01, recurrent_dropout=0.35, return_sequences=True,input_shape=input_shape) )\n","    model.add(LSTM(units=32, dropout=0.01, recurrent_dropout=0.35, return_sequences=False))\n","    model.add(Dense(units=2, activation='sigmoid'))\n","\n","    print(\"Compiling ...\")\n","    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","    model.summary()\n","\n","    print(\"Training ...\")\n","    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=nb_epochs,validation_split=0.33)\n","    score, accuracy = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n","    print(\"Test loss:  \", score)\n","    print(\"Test accuracy:  \", accuracy)\n","\n","    # Summarize history for accuracy\n","    plt.plot(history.history['accuracy'])\n","    plt.plot(history.history['val_accuracy'])\n","    plt.title('model accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.savefig(\"/content/drive/MyDrive/Music-Genre-Classification-master\"+str(count)+\"accuracy\")\n","    plt.close()\n","\n","    # Summarize history for loss\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('model loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.savefig(\"/content/drive/MyDrive/Music-Genre-Classification-master\"+str(count))\n","    plt.close()\n","\n","    count += 1\n","model.save('Model.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8jXIMQRI7V6Y","executionInfo":{"status":"ok","timestamp":1714714903004,"user_tz":240,"elapsed":577845,"user":{"displayName":"Vamsi Manda","userId":"01809937866176487479"}},"outputId":"cbb93ce5-ef5b-41d9-c407-ad4793189e62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape  (9805, 21)\n","y_train shape  (9805,)\n","[[10.6264210892445 -61.96282196044922 119.2556610107422 ...\n","  3.4255645275115967 -3.8072726726531982 -0.095552310347557]\n"," [41.32490839457791 -425.28759765625 126.89898681640624 ...\n","  -1.933012008666992 -0.6390572190284729 4.548562526702881]\n"," [9.163107979146176 -102.97955322265624 166.9093475341797 ...\n","  -1.167567253112793 -0.810927152633667 0.4991808533668518]\n"," ...\n"," [21.718575865449434 -104.3449478149414 127.9443130493164 ...\n","  11.56142807006836 2.412437677383423 5.155041217803955]\n"," [42.165576585869495 -101.73089599609376 173.440185546875 ...\n","  -0.0102514987811446 -0.805259108543396 -3.790855407714844]\n"," [36.81000050649021 -279.3218688964844 143.85426330566406 ...\n","  -3.207831382751465 -3.1452958583831787 -5.238548755645752]]\n","[0 1 0 ... 0 0 1]\n","X_test shape  (9806, 21)\n","y_test shape  (9806,)\n","Compiling ...\n","Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_12 (LSTM)              (None, 1, 64)             22016     \n","                                                                 \n"," lstm_13 (LSTM)              (None, 32)                12416     \n","                                                                 \n"," dense_6 (Dense)             (None, 2)                 66        \n","                                                                 \n","=================================================================\n","Total params: 34498 (134.76 KB)\n","Trainable params: 34498 (134.76 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Training ...\n","Epoch 1/100\n","188/188 [==============================] - 7s 12ms/step - loss: 0.5049 - accuracy: 0.7714 - val_loss: 0.4025 - val_accuracy: 0.8282\n","Epoch 2/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.4009 - accuracy: 0.8240 - val_loss: 0.4003 - val_accuracy: 0.8149\n","Epoch 3/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.3787 - accuracy: 0.8316 - val_loss: 0.3769 - val_accuracy: 0.8316\n","Epoch 4/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.3724 - accuracy: 0.8389 - val_loss: 0.3805 - val_accuracy: 0.8269\n","Epoch 5/100\n","188/188 [==============================] - 2s 10ms/step - loss: 0.3637 - accuracy: 0.8441 - val_loss: 0.3676 - val_accuracy: 0.8300\n","Epoch 6/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.3520 - accuracy: 0.8514 - val_loss: 0.3540 - val_accuracy: 0.8402\n","Epoch 7/100\n","188/188 [==============================] - 2s 10ms/step - loss: 0.3464 - accuracy: 0.8473 - val_loss: 0.3518 - val_accuracy: 0.8455\n","Epoch 8/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.3364 - accuracy: 0.8554 - val_loss: 0.3501 - val_accuracy: 0.8378\n","Epoch 9/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.3323 - accuracy: 0.8577 - val_loss: 0.3375 - val_accuracy: 0.8458\n","Epoch 10/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.3248 - accuracy: 0.8625 - val_loss: 0.3584 - val_accuracy: 0.8337\n","Epoch 11/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.3155 - accuracy: 0.8599 - val_loss: 0.3216 - val_accuracy: 0.8572\n","Epoch 12/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.3133 - accuracy: 0.8628 - val_loss: 0.3331 - val_accuracy: 0.8489\n","Epoch 13/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.3051 - accuracy: 0.8673 - val_loss: 0.3318 - val_accuracy: 0.8498\n","Epoch 14/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.2994 - accuracy: 0.8698 - val_loss: 0.3226 - val_accuracy: 0.8554\n","Epoch 15/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.2925 - accuracy: 0.8746 - val_loss: 0.3133 - val_accuracy: 0.8591\n","Epoch 16/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2939 - accuracy: 0.8720 - val_loss: 0.3149 - val_accuracy: 0.8585\n","Epoch 17/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2886 - accuracy: 0.8770 - val_loss: 0.3105 - val_accuracy: 0.8662\n","Epoch 18/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.2798 - accuracy: 0.8802 - val_loss: 0.3102 - val_accuracy: 0.8662\n","Epoch 19/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.2698 - accuracy: 0.8886 - val_loss: 0.3061 - val_accuracy: 0.8684\n","Epoch 20/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.2627 - accuracy: 0.8916 - val_loss: 0.3441 - val_accuracy: 0.8504\n","Epoch 21/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.2682 - accuracy: 0.8873 - val_loss: 0.2997 - val_accuracy: 0.8711\n","Epoch 22/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.2568 - accuracy: 0.8878 - val_loss: 0.3087 - val_accuracy: 0.8662\n","Epoch 23/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2549 - accuracy: 0.8962 - val_loss: 0.3068 - val_accuracy: 0.8693\n","Epoch 24/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.2531 - accuracy: 0.8904 - val_loss: 0.3005 - val_accuracy: 0.8705\n","Epoch 25/100\n","188/188 [==============================] - 2s 13ms/step - loss: 0.2521 - accuracy: 0.8919 - val_loss: 0.3063 - val_accuracy: 0.8677\n","Epoch 26/100\n","188/188 [==============================] - 3s 14ms/step - loss: 0.2559 - accuracy: 0.8918 - val_loss: 0.2896 - val_accuracy: 0.8770\n","Epoch 27/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2499 - accuracy: 0.8974 - val_loss: 0.2932 - val_accuracy: 0.8748\n","Epoch 28/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.2461 - accuracy: 0.8959 - val_loss: 0.2974 - val_accuracy: 0.8739\n","Epoch 29/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2302 - accuracy: 0.9020 - val_loss: 0.3203 - val_accuracy: 0.8696\n","Epoch 30/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.2389 - accuracy: 0.9004 - val_loss: 0.2893 - val_accuracy: 0.8782\n","Epoch 31/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.2299 - accuracy: 0.9014 - val_loss: 0.3045 - val_accuracy: 0.8687\n","Epoch 32/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2365 - accuracy: 0.9032 - val_loss: 0.3075 - val_accuracy: 0.8721\n","Epoch 33/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.2397 - accuracy: 0.9007 - val_loss: 0.2882 - val_accuracy: 0.8779\n","Epoch 34/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.2303 - accuracy: 0.9015 - val_loss: 0.2844 - val_accuracy: 0.8804\n","Epoch 35/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.2255 - accuracy: 0.9074 - val_loss: 0.2843 - val_accuracy: 0.8841\n","Epoch 36/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.2249 - accuracy: 0.9062 - val_loss: 0.2837 - val_accuracy: 0.8832\n","Epoch 37/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2133 - accuracy: 0.9103 - val_loss: 0.2959 - val_accuracy: 0.8829\n","Epoch 38/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2259 - accuracy: 0.9041 - val_loss: 0.2853 - val_accuracy: 0.8881\n","Epoch 39/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2162 - accuracy: 0.9116 - val_loss: 0.2742 - val_accuracy: 0.8869\n","Epoch 40/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.2238 - accuracy: 0.9047 - val_loss: 0.2876 - val_accuracy: 0.8816\n","Epoch 41/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.2148 - accuracy: 0.9120 - val_loss: 0.2909 - val_accuracy: 0.8813\n","Epoch 42/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.2131 - accuracy: 0.9119 - val_loss: 0.3020 - val_accuracy: 0.8724\n","Epoch 43/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.2060 - accuracy: 0.9143 - val_loss: 0.2905 - val_accuracy: 0.8847\n","Epoch 44/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2130 - accuracy: 0.9140 - val_loss: 0.3067 - val_accuracy: 0.8736\n","Epoch 45/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.2050 - accuracy: 0.9138 - val_loss: 0.2845 - val_accuracy: 0.8847\n","Epoch 46/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2027 - accuracy: 0.9152 - val_loss: 0.2861 - val_accuracy: 0.8844\n","Epoch 47/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2026 - accuracy: 0.9148 - val_loss: 0.2900 - val_accuracy: 0.8807\n","Epoch 48/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1997 - accuracy: 0.9228 - val_loss: 0.2797 - val_accuracy: 0.8798\n","Epoch 49/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1981 - accuracy: 0.9164 - val_loss: 0.2888 - val_accuracy: 0.8813\n","Epoch 50/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2018 - accuracy: 0.9160 - val_loss: 0.2836 - val_accuracy: 0.8869\n","Epoch 51/100\n","188/188 [==============================] - 2s 13ms/step - loss: 0.1990 - accuracy: 0.9208 - val_loss: 0.2766 - val_accuracy: 0.8928\n","Epoch 52/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.2056 - accuracy: 0.9144 - val_loss: 0.2791 - val_accuracy: 0.8943\n","Epoch 53/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.1907 - accuracy: 0.9216 - val_loss: 0.2995 - val_accuracy: 0.8782\n","Epoch 54/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.2034 - accuracy: 0.9195 - val_loss: 0.2794 - val_accuracy: 0.8841\n","Epoch 55/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.1881 - accuracy: 0.9222 - val_loss: 0.2711 - val_accuracy: 0.8943\n","Epoch 56/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1847 - accuracy: 0.9224 - val_loss: 0.2861 - val_accuracy: 0.8872\n","Epoch 57/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1955 - accuracy: 0.9175 - val_loss: 0.2944 - val_accuracy: 0.8820\n","Epoch 58/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1915 - accuracy: 0.9214 - val_loss: 0.2777 - val_accuracy: 0.8894\n","Epoch 59/100\n","188/188 [==============================] - 2s 10ms/step - loss: 0.1821 - accuracy: 0.9236 - val_loss: 0.2762 - val_accuracy: 0.8906\n","Epoch 60/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.1884 - accuracy: 0.9240 - val_loss: 0.2867 - val_accuracy: 0.8866\n","Epoch 61/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1780 - accuracy: 0.9260 - val_loss: 0.2936 - val_accuracy: 0.8789\n","Epoch 62/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1791 - accuracy: 0.9286 - val_loss: 0.2770 - val_accuracy: 0.8869\n","Epoch 63/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1847 - accuracy: 0.9254 - val_loss: 0.2838 - val_accuracy: 0.8925\n","Epoch 64/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1731 - accuracy: 0.9303 - val_loss: 0.2662 - val_accuracy: 0.8999\n","Epoch 65/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1769 - accuracy: 0.9312 - val_loss: 0.2789 - val_accuracy: 0.8956\n","Epoch 66/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1705 - accuracy: 0.9277 - val_loss: 0.2796 - val_accuracy: 0.8946\n","Epoch 67/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1830 - accuracy: 0.9248 - val_loss: 0.2745 - val_accuracy: 0.8906\n","Epoch 68/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.1746 - accuracy: 0.9329 - val_loss: 0.2721 - val_accuracy: 0.8909\n","Epoch 69/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.1732 - accuracy: 0.9297 - val_loss: 0.2768 - val_accuracy: 0.8925\n","Epoch 70/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1684 - accuracy: 0.9336 - val_loss: 0.2893 - val_accuracy: 0.8878\n","Epoch 71/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1706 - accuracy: 0.9327 - val_loss: 0.2775 - val_accuracy: 0.8915\n","Epoch 72/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.1681 - accuracy: 0.9320 - val_loss: 0.2759 - val_accuracy: 0.8915\n","Epoch 73/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1724 - accuracy: 0.9271 - val_loss: 0.2809 - val_accuracy: 0.8949\n","Epoch 74/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1616 - accuracy: 0.9359 - val_loss: 0.2861 - val_accuracy: 0.8922\n","Epoch 75/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1712 - accuracy: 0.9285 - val_loss: 0.2811 - val_accuracy: 0.8860\n","Epoch 76/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1716 - accuracy: 0.9292 - val_loss: 0.2804 - val_accuracy: 0.8906\n","Epoch 77/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.1608 - accuracy: 0.9338 - val_loss: 0.2739 - val_accuracy: 0.8977\n","Epoch 78/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.1691 - accuracy: 0.9323 - val_loss: 0.2776 - val_accuracy: 0.8971\n","Epoch 79/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1636 - accuracy: 0.9348 - val_loss: 0.2723 - val_accuracy: 0.8974\n","Epoch 80/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1637 - accuracy: 0.9336 - val_loss: 0.2863 - val_accuracy: 0.8884\n","Epoch 81/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1624 - accuracy: 0.9348 - val_loss: 0.2773 - val_accuracy: 0.8940\n","Epoch 82/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1605 - accuracy: 0.9347 - val_loss: 0.2804 - val_accuracy: 0.8940\n","Epoch 83/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.1575 - accuracy: 0.9394 - val_loss: 0.2865 - val_accuracy: 0.8881\n","Epoch 84/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1556 - accuracy: 0.9394 - val_loss: 0.2876 - val_accuracy: 0.8959\n","Epoch 85/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.1524 - accuracy: 0.9402 - val_loss: 0.2872 - val_accuracy: 0.8943\n","Epoch 86/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.1665 - accuracy: 0.9341 - val_loss: 0.3006 - val_accuracy: 0.8866\n","Epoch 87/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.1617 - accuracy: 0.9365 - val_loss: 0.2784 - val_accuracy: 0.8962\n","Epoch 88/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1524 - accuracy: 0.9420 - val_loss: 0.2933 - val_accuracy: 0.8854\n","Epoch 89/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1567 - accuracy: 0.9356 - val_loss: 0.2722 - val_accuracy: 0.8959\n","Epoch 90/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.1676 - accuracy: 0.9332 - val_loss: 0.3003 - val_accuracy: 0.8863\n","Epoch 91/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1452 - accuracy: 0.9452 - val_loss: 0.2777 - val_accuracy: 0.8971\n","Epoch 92/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1487 - accuracy: 0.9425 - val_loss: 0.2897 - val_accuracy: 0.8900\n","Epoch 93/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1488 - accuracy: 0.9434 - val_loss: 0.3040 - val_accuracy: 0.8891\n","Epoch 94/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1482 - accuracy: 0.9411 - val_loss: 0.2883 - val_accuracy: 0.8918\n","Epoch 95/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.1543 - accuracy: 0.9332 - val_loss: 0.2952 - val_accuracy: 0.8940\n","Epoch 96/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.1570 - accuracy: 0.9379 - val_loss: 0.2803 - val_accuracy: 0.8956\n","Epoch 97/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1545 - accuracy: 0.9373 - val_loss: 0.2968 - val_accuracy: 0.8934\n","Epoch 98/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1523 - accuracy: 0.9406 - val_loss: 0.2772 - val_accuracy: 0.8999\n","Epoch 99/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1493 - accuracy: 0.9444 - val_loss: 0.2827 - val_accuracy: 0.8968\n","Epoch 100/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.1400 - accuracy: 0.9452 - val_loss: 0.3093 - val_accuracy: 0.8820\n","281/281 [==============================] - 1s 2ms/step - loss: 0.2980 - accuracy: 0.8833\n","Test loss:   0.2979748249053955\n","Test accuracy:   0.8833367228507996\n","Compiling ...\n","Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_14 (LSTM)              (None, 1, 64)             22016     \n","                                                                 \n"," lstm_15 (LSTM)              (None, 32)                12416     \n","                                                                 \n"," dense_7 (Dense)             (None, 2)                 66        \n","                                                                 \n","=================================================================\n","Total params: 34498 (134.76 KB)\n","Trainable params: 34498 (134.76 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Training ...\n","Epoch 1/100\n","188/188 [==============================] - 10s 12ms/step - loss: 0.4569 - accuracy: 0.7858 - val_loss: 0.3966 - val_accuracy: 0.8205\n","Epoch 2/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.4006 - accuracy: 0.8211 - val_loss: 0.3854 - val_accuracy: 0.8254\n","Epoch 3/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.3816 - accuracy: 0.8262 - val_loss: 0.3710 - val_accuracy: 0.8288\n","Epoch 4/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.3727 - accuracy: 0.8325 - val_loss: 0.3656 - val_accuracy: 0.8294\n","Epoch 5/100\n","188/188 [==============================] - 3s 14ms/step - loss: 0.3605 - accuracy: 0.8374 - val_loss: 0.3640 - val_accuracy: 0.8319\n","Epoch 6/100\n","188/188 [==============================] - 2s 10ms/step - loss: 0.3581 - accuracy: 0.8412 - val_loss: 0.3552 - val_accuracy: 0.8313\n","Epoch 7/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.3457 - accuracy: 0.8459 - val_loss: 0.3499 - val_accuracy: 0.8393\n","Epoch 8/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.3377 - accuracy: 0.8526 - val_loss: 0.3489 - val_accuracy: 0.8322\n","Epoch 9/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.3341 - accuracy: 0.8529 - val_loss: 0.3399 - val_accuracy: 0.8381\n","Epoch 10/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.3269 - accuracy: 0.8552 - val_loss: 0.3355 - val_accuracy: 0.8412\n","Epoch 11/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.3191 - accuracy: 0.8596 - val_loss: 0.3354 - val_accuracy: 0.8409\n","Epoch 12/100\n","188/188 [==============================] - 2s 10ms/step - loss: 0.3172 - accuracy: 0.8578 - val_loss: 0.3257 - val_accuracy: 0.8461\n","Epoch 13/100\n","188/188 [==============================] - 2s 13ms/step - loss: 0.3064 - accuracy: 0.8607 - val_loss: 0.3373 - val_accuracy: 0.8452\n","Epoch 14/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.3047 - accuracy: 0.8694 - val_loss: 0.3199 - val_accuracy: 0.8560\n","Epoch 15/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.3049 - accuracy: 0.8651 - val_loss: 0.3370 - val_accuracy: 0.8461\n","Epoch 16/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2994 - accuracy: 0.8733 - val_loss: 0.3208 - val_accuracy: 0.8507\n","Epoch 17/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2937 - accuracy: 0.8717 - val_loss: 0.3131 - val_accuracy: 0.8563\n","Epoch 18/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2934 - accuracy: 0.8715 - val_loss: 0.3196 - val_accuracy: 0.8501\n","Epoch 19/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.2825 - accuracy: 0.8762 - val_loss: 0.3343 - val_accuracy: 0.8480\n","Epoch 20/100\n","188/188 [==============================] - 2s 10ms/step - loss: 0.2827 - accuracy: 0.8776 - val_loss: 0.3093 - val_accuracy: 0.8600\n","Epoch 21/100\n","188/188 [==============================] - 3s 14ms/step - loss: 0.2769 - accuracy: 0.8807 - val_loss: 0.3143 - val_accuracy: 0.8541\n","Epoch 22/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2815 - accuracy: 0.8814 - val_loss: 0.3094 - val_accuracy: 0.8578\n","Epoch 23/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.2767 - accuracy: 0.8829 - val_loss: 0.3075 - val_accuracy: 0.8569\n","Epoch 24/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2763 - accuracy: 0.8829 - val_loss: 0.3146 - val_accuracy: 0.8575\n","Epoch 25/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.2756 - accuracy: 0.8831 - val_loss: 0.3175 - val_accuracy: 0.8591\n","Epoch 26/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2708 - accuracy: 0.8848 - val_loss: 0.3047 - val_accuracy: 0.8671\n","Epoch 27/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2639 - accuracy: 0.8860 - val_loss: 0.3040 - val_accuracy: 0.8625\n","Epoch 28/100\n","188/188 [==============================] - 2s 10ms/step - loss: 0.2660 - accuracy: 0.8864 - val_loss: 0.3090 - val_accuracy: 0.8671\n","Epoch 29/100\n","188/188 [==============================] - 2s 13ms/step - loss: 0.2616 - accuracy: 0.8904 - val_loss: 0.3175 - val_accuracy: 0.8557\n","Epoch 30/100\n","188/188 [==============================] - 2s 10ms/step - loss: 0.2529 - accuracy: 0.8918 - val_loss: 0.3025 - val_accuracy: 0.8643\n","Epoch 31/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2585 - accuracy: 0.8893 - val_loss: 0.3007 - val_accuracy: 0.8736\n","Epoch 32/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2482 - accuracy: 0.8956 - val_loss: 0.2975 - val_accuracy: 0.8711\n","Epoch 33/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2552 - accuracy: 0.8922 - val_loss: 0.2963 - val_accuracy: 0.8736\n","Epoch 34/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2513 - accuracy: 0.8939 - val_loss: 0.3138 - val_accuracy: 0.8575\n","Epoch 35/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.2490 - accuracy: 0.8940 - val_loss: 0.3030 - val_accuracy: 0.8631\n","Epoch 36/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2431 - accuracy: 0.8966 - val_loss: 0.2930 - val_accuracy: 0.8718\n","Epoch 37/100\n","188/188 [==============================] - 2s 13ms/step - loss: 0.2503 - accuracy: 0.8944 - val_loss: 0.2917 - val_accuracy: 0.8708\n","Epoch 38/100\n","188/188 [==============================] - 3s 15ms/step - loss: 0.2376 - accuracy: 0.9000 - val_loss: 0.2915 - val_accuracy: 0.8718\n","Epoch 39/100\n","188/188 [==============================] - 3s 13ms/step - loss: 0.2462 - accuracy: 0.9007 - val_loss: 0.2865 - val_accuracy: 0.8705\n","Epoch 40/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2461 - accuracy: 0.8948 - val_loss: 0.2912 - val_accuracy: 0.8684\n","Epoch 41/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2361 - accuracy: 0.9026 - val_loss: 0.2944 - val_accuracy: 0.8674\n","Epoch 42/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.2359 - accuracy: 0.9030 - val_loss: 0.2889 - val_accuracy: 0.8718\n","Epoch 43/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2379 - accuracy: 0.8994 - val_loss: 0.2925 - val_accuracy: 0.8708\n","Epoch 44/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2344 - accuracy: 0.9035 - val_loss: 0.3057 - val_accuracy: 0.8578\n","Epoch 45/100\n","188/188 [==============================] - 2s 13ms/step - loss: 0.2268 - accuracy: 0.9042 - val_loss: 0.2934 - val_accuracy: 0.8699\n","Epoch 46/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.2244 - accuracy: 0.9053 - val_loss: 0.2996 - val_accuracy: 0.8677\n","Epoch 47/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2249 - accuracy: 0.9111 - val_loss: 0.2986 - val_accuracy: 0.8727\n","Epoch 48/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.2209 - accuracy: 0.9122 - val_loss: 0.2961 - val_accuracy: 0.8718\n","Epoch 49/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2189 - accuracy: 0.9088 - val_loss: 0.2960 - val_accuracy: 0.8736\n","Epoch 50/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2241 - accuracy: 0.9088 - val_loss: 0.3038 - val_accuracy: 0.8668\n","Epoch 51/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2214 - accuracy: 0.9035 - val_loss: 0.3031 - val_accuracy: 0.8671\n","Epoch 52/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.2204 - accuracy: 0.9079 - val_loss: 0.2938 - val_accuracy: 0.8721\n","Epoch 53/100\n","188/188 [==============================] - 3s 14ms/step - loss: 0.2178 - accuracy: 0.9099 - val_loss: 0.2951 - val_accuracy: 0.8755\n","Epoch 54/100\n","188/188 [==============================] - 2s 10ms/step - loss: 0.2253 - accuracy: 0.9079 - val_loss: 0.2907 - val_accuracy: 0.8764\n","Epoch 55/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2154 - accuracy: 0.9109 - val_loss: 0.2991 - val_accuracy: 0.8690\n","Epoch 56/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2179 - accuracy: 0.9059 - val_loss: 0.2844 - val_accuracy: 0.8742\n","Epoch 57/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2122 - accuracy: 0.9116 - val_loss: 0.2988 - val_accuracy: 0.8776\n","Epoch 58/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2121 - accuracy: 0.9140 - val_loss: 0.3058 - val_accuracy: 0.8690\n","Epoch 59/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.2176 - accuracy: 0.9116 - val_loss: 0.2982 - val_accuracy: 0.8736\n","Epoch 60/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.2134 - accuracy: 0.9135 - val_loss: 0.3125 - val_accuracy: 0.8696\n","Epoch 61/100\n","188/188 [==============================] - 3s 15ms/step - loss: 0.2004 - accuracy: 0.9155 - val_loss: 0.2977 - val_accuracy: 0.8727\n","Epoch 62/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2197 - accuracy: 0.9094 - val_loss: 0.2940 - val_accuracy: 0.8758\n","Epoch 63/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2164 - accuracy: 0.9111 - val_loss: 0.2905 - val_accuracy: 0.8708\n","Epoch 64/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2026 - accuracy: 0.9167 - val_loss: 0.2983 - val_accuracy: 0.8714\n","Epoch 65/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2078 - accuracy: 0.9172 - val_loss: 0.2979 - val_accuracy: 0.8724\n","Epoch 66/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2028 - accuracy: 0.9173 - val_loss: 0.2948 - val_accuracy: 0.8742\n","Epoch 67/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2044 - accuracy: 0.9144 - val_loss: 0.2926 - val_accuracy: 0.8745\n","Epoch 68/100\n","188/188 [==============================] - 2s 13ms/step - loss: 0.2037 - accuracy: 0.9146 - val_loss: 0.2995 - val_accuracy: 0.8782\n","Epoch 69/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.2109 - accuracy: 0.9144 - val_loss: 0.2945 - val_accuracy: 0.8764\n","Epoch 70/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2005 - accuracy: 0.9208 - val_loss: 0.2938 - val_accuracy: 0.8801\n","Epoch 71/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2072 - accuracy: 0.9125 - val_loss: 0.3040 - val_accuracy: 0.8776\n","Epoch 72/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2062 - accuracy: 0.9138 - val_loss: 0.3047 - val_accuracy: 0.8702\n","Epoch 73/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1976 - accuracy: 0.9175 - val_loss: 0.3081 - val_accuracy: 0.8708\n","Epoch 74/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2007 - accuracy: 0.9184 - val_loss: 0.2929 - val_accuracy: 0.8770\n","Epoch 75/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1982 - accuracy: 0.9202 - val_loss: 0.2979 - val_accuracy: 0.8745\n","Epoch 76/100\n","188/188 [==============================] - 3s 15ms/step - loss: 0.1990 - accuracy: 0.9198 - val_loss: 0.3032 - val_accuracy: 0.8739\n","Epoch 77/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.1962 - accuracy: 0.9183 - val_loss: 0.2979 - val_accuracy: 0.8727\n","Epoch 78/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1948 - accuracy: 0.9199 - val_loss: 0.3010 - val_accuracy: 0.8748\n","Epoch 79/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1996 - accuracy: 0.9195 - val_loss: 0.2916 - val_accuracy: 0.8755\n","Epoch 80/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1956 - accuracy: 0.9242 - val_loss: 0.3168 - val_accuracy: 0.8665\n","Epoch 81/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1931 - accuracy: 0.9186 - val_loss: 0.2975 - val_accuracy: 0.8752\n","Epoch 82/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1921 - accuracy: 0.9207 - val_loss: 0.2962 - val_accuracy: 0.8764\n","Epoch 83/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.1900 - accuracy: 0.9234 - val_loss: 0.2971 - val_accuracy: 0.8733\n","Epoch 84/100\n","188/188 [==============================] - 3s 15ms/step - loss: 0.1876 - accuracy: 0.9227 - val_loss: 0.2960 - val_accuracy: 0.8761\n","Epoch 85/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1948 - accuracy: 0.9214 - val_loss: 0.3128 - val_accuracy: 0.8671\n","Epoch 86/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1898 - accuracy: 0.9208 - val_loss: 0.2941 - val_accuracy: 0.8847\n","Epoch 87/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1812 - accuracy: 0.9277 - val_loss: 0.2918 - val_accuracy: 0.8792\n","Epoch 88/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1865 - accuracy: 0.9189 - val_loss: 0.3010 - val_accuracy: 0.8764\n","Epoch 89/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1937 - accuracy: 0.9234 - val_loss: 0.2948 - val_accuracy: 0.8776\n","Epoch 90/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1800 - accuracy: 0.9257 - val_loss: 0.2916 - val_accuracy: 0.8798\n","Epoch 91/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.1831 - accuracy: 0.9230 - val_loss: 0.2981 - val_accuracy: 0.8801\n","Epoch 92/100\n","188/188 [==============================] - 2s 13ms/step - loss: 0.1785 - accuracy: 0.9320 - val_loss: 0.2974 - val_accuracy: 0.8748\n","Epoch 93/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1772 - accuracy: 0.9285 - val_loss: 0.3152 - val_accuracy: 0.8727\n","Epoch 94/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1897 - accuracy: 0.9231 - val_loss: 0.3058 - val_accuracy: 0.8789\n","Epoch 95/100\n","188/188 [==============================] - 2s 13ms/step - loss: 0.1730 - accuracy: 0.9304 - val_loss: 0.2983 - val_accuracy: 0.8826\n","Epoch 96/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.1787 - accuracy: 0.9274 - val_loss: 0.2950 - val_accuracy: 0.8792\n","Epoch 97/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1872 - accuracy: 0.9271 - val_loss: 0.3017 - val_accuracy: 0.8745\n","Epoch 98/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.1786 - accuracy: 0.9289 - val_loss: 0.3029 - val_accuracy: 0.8755\n","Epoch 99/100\n","188/188 [==============================] - 3s 15ms/step - loss: 0.1843 - accuracy: 0.9254 - val_loss: 0.2823 - val_accuracy: 0.8801\n","Epoch 100/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1765 - accuracy: 0.9298 - val_loss: 0.3016 - val_accuracy: 0.8773\n","281/281 [==============================] - 1s 3ms/step - loss: 0.2706 - accuracy: 0.8888\n","Test loss:   0.2705959379673004\n","Test accuracy:   0.8888435363769531\n","Compiling ...\n","Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_16 (LSTM)              (None, 1, 64)             22016     \n","                                                                 \n"," lstm_17 (LSTM)              (None, 32)                12416     \n","                                                                 \n"," dense_8 (Dense)             (None, 2)                 66        \n","                                                                 \n","=================================================================\n","Total params: 34498 (134.76 KB)\n","Trainable params: 34498 (134.76 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Training ...\n","Epoch 1/100\n","188/188 [==============================] - 9s 14ms/step - loss: 0.4504 - accuracy: 0.7858 - val_loss: 0.3907 - val_accuracy: 0.8325\n","Epoch 2/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.3917 - accuracy: 0.8278 - val_loss: 0.3702 - val_accuracy: 0.8480\n","Epoch 3/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.3692 - accuracy: 0.8399 - val_loss: 0.4054 - val_accuracy: 0.8167\n","Epoch 4/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.3610 - accuracy: 0.8389 - val_loss: 0.3573 - val_accuracy: 0.8436\n","Epoch 5/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.3541 - accuracy: 0.8455 - val_loss: 0.3571 - val_accuracy: 0.8405\n","Epoch 6/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.3488 - accuracy: 0.8415 - val_loss: 0.3442 - val_accuracy: 0.8492\n","Epoch 7/100\n","188/188 [==============================] - 2s 10ms/step - loss: 0.3354 - accuracy: 0.8529 - val_loss: 0.3393 - val_accuracy: 0.8477\n","Epoch 8/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.3349 - accuracy: 0.8548 - val_loss: 0.3435 - val_accuracy: 0.8439\n","Epoch 9/100\n","188/188 [==============================] - 2s 10ms/step - loss: 0.3242 - accuracy: 0.8606 - val_loss: 0.3427 - val_accuracy: 0.8458\n","Epoch 10/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.3295 - accuracy: 0.8561 - val_loss: 0.3428 - val_accuracy: 0.8498\n","Epoch 11/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.3130 - accuracy: 0.8654 - val_loss: 0.3339 - val_accuracy: 0.8486\n","Epoch 12/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.3140 - accuracy: 0.8688 - val_loss: 0.3403 - val_accuracy: 0.8461\n","Epoch 13/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.3179 - accuracy: 0.8590 - val_loss: 0.3255 - val_accuracy: 0.8529\n","Epoch 14/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.3061 - accuracy: 0.8698 - val_loss: 0.3214 - val_accuracy: 0.8541\n","Epoch 15/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.3050 - accuracy: 0.8689 - val_loss: 0.3263 - val_accuracy: 0.8529\n","Epoch 16/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.2976 - accuracy: 0.8729 - val_loss: 0.3335 - val_accuracy: 0.8526\n","Epoch 17/100\n","188/188 [==============================] - 2s 13ms/step - loss: 0.2886 - accuracy: 0.8772 - val_loss: 0.3170 - val_accuracy: 0.8591\n","Epoch 18/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2898 - accuracy: 0.8775 - val_loss: 0.3355 - val_accuracy: 0.8452\n","Epoch 19/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2897 - accuracy: 0.8807 - val_loss: 0.3662 - val_accuracy: 0.8415\n","Epoch 20/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2927 - accuracy: 0.8767 - val_loss: 0.3195 - val_accuracy: 0.8551\n","Epoch 21/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.2850 - accuracy: 0.8776 - val_loss: 0.3195 - val_accuracy: 0.8554\n","Epoch 22/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2824 - accuracy: 0.8785 - val_loss: 0.3114 - val_accuracy: 0.8591\n","Epoch 23/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2815 - accuracy: 0.8807 - val_loss: 0.3117 - val_accuracy: 0.8625\n","Epoch 24/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.2735 - accuracy: 0.8837 - val_loss: 0.3100 - val_accuracy: 0.8582\n","Epoch 25/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.2697 - accuracy: 0.8808 - val_loss: 0.3158 - val_accuracy: 0.8566\n","Epoch 26/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2665 - accuracy: 0.8842 - val_loss: 0.3066 - val_accuracy: 0.8637\n","Epoch 27/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2633 - accuracy: 0.8857 - val_loss: 0.3149 - val_accuracy: 0.8628\n","Epoch 28/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.2658 - accuracy: 0.8852 - val_loss: 0.2993 - val_accuracy: 0.8637\n","Epoch 29/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2575 - accuracy: 0.8890 - val_loss: 0.3083 - val_accuracy: 0.8619\n","Epoch 30/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.2564 - accuracy: 0.8884 - val_loss: 0.3073 - val_accuracy: 0.8637\n","Epoch 31/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.2628 - accuracy: 0.8870 - val_loss: 0.3103 - val_accuracy: 0.8609\n","Epoch 32/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2545 - accuracy: 0.8930 - val_loss: 0.3071 - val_accuracy: 0.8609\n","Epoch 33/100\n","188/188 [==============================] - 2s 13ms/step - loss: 0.2525 - accuracy: 0.8909 - val_loss: 0.3086 - val_accuracy: 0.8569\n","Epoch 34/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.2520 - accuracy: 0.8931 - val_loss: 0.3145 - val_accuracy: 0.8591\n","Epoch 35/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2462 - accuracy: 0.8939 - val_loss: 0.3145 - val_accuracy: 0.8600\n","Epoch 36/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2453 - accuracy: 0.8954 - val_loss: 0.3016 - val_accuracy: 0.8677\n","Epoch 37/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.2387 - accuracy: 0.8985 - val_loss: 0.3080 - val_accuracy: 0.8671\n","Epoch 38/100\n","188/188 [==============================] - 2s 13ms/step - loss: 0.2459 - accuracy: 0.8968 - val_loss: 0.3083 - val_accuracy: 0.8680\n","Epoch 39/100\n","188/188 [==============================] - 1s 7ms/step - loss: 0.2367 - accuracy: 0.8986 - val_loss: 0.3302 - val_accuracy: 0.8588\n","Epoch 40/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.2413 - accuracy: 0.8950 - val_loss: 0.2959 - val_accuracy: 0.8668\n","Epoch 41/100\n","188/188 [==============================] - 2s 13ms/step - loss: 0.2328 - accuracy: 0.9014 - val_loss: 0.3029 - val_accuracy: 0.8674\n","Epoch 42/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2314 - accuracy: 0.8995 - val_loss: 0.3026 - val_accuracy: 0.8684\n","Epoch 43/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2333 - accuracy: 0.8988 - val_loss: 0.3018 - val_accuracy: 0.8674\n","Epoch 44/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2390 - accuracy: 0.9000 - val_loss: 0.3060 - val_accuracy: 0.8656\n","Epoch 45/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2398 - accuracy: 0.8975 - val_loss: 0.3016 - val_accuracy: 0.8693\n","Epoch 46/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2270 - accuracy: 0.9046 - val_loss: 0.3121 - val_accuracy: 0.8653\n","Epoch 47/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2247 - accuracy: 0.9035 - val_loss: 0.3066 - val_accuracy: 0.8733\n","Epoch 48/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.2217 - accuracy: 0.9062 - val_loss: 0.3119 - val_accuracy: 0.8714\n","Epoch 49/100\n","188/188 [==============================] - 2s 13ms/step - loss: 0.2295 - accuracy: 0.9017 - val_loss: 0.3038 - val_accuracy: 0.8684\n","Epoch 50/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2208 - accuracy: 0.9027 - val_loss: 0.3120 - val_accuracy: 0.8631\n","Epoch 51/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2223 - accuracy: 0.9055 - val_loss: 0.3062 - val_accuracy: 0.8718\n","Epoch 52/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2198 - accuracy: 0.9073 - val_loss: 0.3392 - val_accuracy: 0.8560\n","Epoch 53/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2225 - accuracy: 0.9076 - val_loss: 0.3160 - val_accuracy: 0.8727\n","Epoch 54/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2183 - accuracy: 0.9077 - val_loss: 0.3020 - val_accuracy: 0.8724\n","Epoch 55/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2115 - accuracy: 0.9106 - val_loss: 0.3054 - val_accuracy: 0.8764\n","Epoch 56/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.2130 - accuracy: 0.9154 - val_loss: 0.3050 - val_accuracy: 0.8727\n","Epoch 57/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.2142 - accuracy: 0.9116 - val_loss: 0.3127 - val_accuracy: 0.8718\n","Epoch 58/100\n","188/188 [==============================] - 2s 10ms/step - loss: 0.2055 - accuracy: 0.9131 - val_loss: 0.3091 - val_accuracy: 0.8742\n","Epoch 59/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2105 - accuracy: 0.9128 - val_loss: 0.2971 - val_accuracy: 0.8752\n","Epoch 60/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2062 - accuracy: 0.9149 - val_loss: 0.3129 - val_accuracy: 0.8693\n","Epoch 61/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2026 - accuracy: 0.9160 - val_loss: 0.3032 - val_accuracy: 0.8761\n","Epoch 62/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2085 - accuracy: 0.9151 - val_loss: 0.3004 - val_accuracy: 0.8795\n","Epoch 63/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2023 - accuracy: 0.9152 - val_loss: 0.3197 - val_accuracy: 0.8714\n","Epoch 64/100\n","188/188 [==============================] - 2s 10ms/step - loss: 0.2078 - accuracy: 0.9143 - val_loss: 0.3017 - val_accuracy: 0.8724\n","Epoch 65/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.2026 - accuracy: 0.9141 - val_loss: 0.3273 - val_accuracy: 0.8650\n","Epoch 66/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.2004 - accuracy: 0.9193 - val_loss: 0.2915 - val_accuracy: 0.8792\n","Epoch 67/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.2065 - accuracy: 0.9131 - val_loss: 0.3044 - val_accuracy: 0.8782\n","Epoch 68/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1954 - accuracy: 0.9195 - val_loss: 0.3158 - val_accuracy: 0.8745\n","Epoch 69/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1927 - accuracy: 0.9211 - val_loss: 0.3047 - val_accuracy: 0.8733\n","Epoch 70/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1961 - accuracy: 0.9207 - val_loss: 0.3096 - val_accuracy: 0.8705\n","Epoch 71/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.2016 - accuracy: 0.9151 - val_loss: 0.3013 - val_accuracy: 0.8739\n","Epoch 72/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1985 - accuracy: 0.9195 - val_loss: 0.2973 - val_accuracy: 0.8755\n","Epoch 73/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.1909 - accuracy: 0.9193 - val_loss: 0.3079 - val_accuracy: 0.8755\n","Epoch 74/100\n","188/188 [==============================] - 3s 15ms/step - loss: 0.1953 - accuracy: 0.9195 - val_loss: 0.3073 - val_accuracy: 0.8755\n","Epoch 75/100\n","188/188 [==============================] - 3s 14ms/step - loss: 0.1947 - accuracy: 0.9216 - val_loss: 0.2974 - val_accuracy: 0.8829\n","Epoch 76/100\n","188/188 [==============================] - 2s 10ms/step - loss: 0.2022 - accuracy: 0.9181 - val_loss: 0.3058 - val_accuracy: 0.8699\n","Epoch 77/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1876 - accuracy: 0.9254 - val_loss: 0.3041 - val_accuracy: 0.8748\n","Epoch 78/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1835 - accuracy: 0.9236 - val_loss: 0.3093 - val_accuracy: 0.8789\n","Epoch 79/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1932 - accuracy: 0.9228 - val_loss: 0.2991 - val_accuracy: 0.8770\n","Epoch 80/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.1914 - accuracy: 0.9230 - val_loss: 0.3180 - val_accuracy: 0.8752\n","Epoch 81/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.1764 - accuracy: 0.9300 - val_loss: 0.3259 - val_accuracy: 0.8699\n","Epoch 82/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.1879 - accuracy: 0.9263 - val_loss: 0.3088 - val_accuracy: 0.8730\n","Epoch 83/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1810 - accuracy: 0.9240 - val_loss: 0.3308 - val_accuracy: 0.8656\n","Epoch 84/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1826 - accuracy: 0.9257 - val_loss: 0.3067 - val_accuracy: 0.8782\n","Epoch 85/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1848 - accuracy: 0.9263 - val_loss: 0.3380 - val_accuracy: 0.8680\n","Epoch 86/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1798 - accuracy: 0.9275 - val_loss: 0.3076 - val_accuracy: 0.8776\n","Epoch 87/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1726 - accuracy: 0.9303 - val_loss: 0.3314 - val_accuracy: 0.8721\n","Epoch 88/100\n","188/188 [==============================] - 2s 10ms/step - loss: 0.1824 - accuracy: 0.9310 - val_loss: 0.3167 - val_accuracy: 0.8782\n","Epoch 89/100\n","188/188 [==============================] - 2s 13ms/step - loss: 0.1936 - accuracy: 0.9242 - val_loss: 0.2932 - val_accuracy: 0.8838\n","Epoch 90/100\n","188/188 [==============================] - 2s 11ms/step - loss: 0.1771 - accuracy: 0.9304 - val_loss: 0.2941 - val_accuracy: 0.8807\n","Epoch 91/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1756 - accuracy: 0.9268 - val_loss: 0.3069 - val_accuracy: 0.8823\n","Epoch 92/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1849 - accuracy: 0.9263 - val_loss: 0.3129 - val_accuracy: 0.8687\n","Epoch 93/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1785 - accuracy: 0.9310 - val_loss: 0.3185 - val_accuracy: 0.8708\n","Epoch 94/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1790 - accuracy: 0.9303 - val_loss: 0.3021 - val_accuracy: 0.8764\n","Epoch 95/100\n","188/188 [==============================] - 2s 8ms/step - loss: 0.1719 - accuracy: 0.9312 - val_loss: 0.3076 - val_accuracy: 0.8767\n","Epoch 96/100\n","188/188 [==============================] - 2s 12ms/step - loss: 0.1729 - accuracy: 0.9316 - val_loss: 0.3144 - val_accuracy: 0.8767\n","Epoch 97/100\n","188/188 [==============================] - 3s 14ms/step - loss: 0.1778 - accuracy: 0.9291 - val_loss: 0.3088 - val_accuracy: 0.8779\n","Epoch 98/100\n","188/188 [==============================] - 2s 10ms/step - loss: 0.1751 - accuracy: 0.9321 - val_loss: 0.3159 - val_accuracy: 0.8705\n","Epoch 99/100\n","188/188 [==============================] - 2s 9ms/step - loss: 0.1704 - accuracy: 0.9336 - val_loss: 0.3055 - val_accuracy: 0.8835\n","Epoch 100/100\n","188/188 [==============================] - 1s 8ms/step - loss: 0.1737 - accuracy: 0.9318 - val_loss: 0.3181 - val_accuracy: 0.8804\n","281/281 [==============================] - 1s 3ms/step - loss: 0.3028 - accuracy: 0.8880\n","Test loss:   0.30284765362739563\n","Test accuracy:   0.8880277276039124\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","\n","# Predict probabilities for test set\n","y_pred_probs = model.predict(x_test)\n","# Convert probabilities to class labels\n","y_pred = np.argmax(y_pred_probs, axis=1)\n","# Convert one-hot encoded labels back to single column\n","y_true = np.argmax(y_test, axis=1)\n","\n","# Calculate confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred)\n","\n","# Print confusion matrix\n","print(\"Confusion Matrix:\")\n","print(conf_matrix)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lnPtiFSf6KoC","executionInfo":{"status":"ok","timestamp":1714710494170,"user_tz":240,"elapsed":1996,"user":{"displayName":"Vamsi Manda","userId":"01809937866176487479"}},"outputId":"e5245b16-dce3-485c-faeb-511c88d5ea12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["307/307 [==============================] - 1s 2ms/step\n","Confusion Matrix:\n","[[4441  608]\n"," [ 464 4293]]\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sn\n","from sklearn.metrics import confusion_matrix\n","# Calculate confusion matrix\n","confusion_matrix = confusion_matrix(y_true, y_pred)\n","# Define class labels for better visualization\n","class_names = [\"Prog\", \"Non-Prog\"]\n","\n","# Create DataFrame for confusion matrix\n","df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names)\n","\n","# Plot confusion matrix using seaborn heatmap\n","plt.figure(figsize=(7, 4))\n","sn.heatmap(df_cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n","           annot_kws={\"size\": 16}, linewidths=0.5, linecolor='black')\n","\n","# Customize plot\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.xticks(np.arange(len(class_names)) + 0.5, class_names, rotation=45)\n","plt.yticks(np.arange(len(class_names)) + 0.5, class_names, rotation=0)\n","\n","# Display plot\n","plt.tight_layout()\n","display(plt.show())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"mCP1sqa_AToV","executionInfo":{"status":"ok","timestamp":1714715467075,"user_tz":240,"elapsed":239,"user":{"displayName":"Vamsi Manda","userId":"01809937866176487479"}},"outputId":"cf9e7210-8e3c-43e3-d62d-8e2ecea9a0fe"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["None"]},"metadata":{}}]},{"cell_type":"code","source":["print(y_true)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rm5JbVHh_faI","executionInfo":{"status":"ok","timestamp":1714715322344,"user_tz":240,"elapsed":176,"user":{"displayName":"Vamsi Manda","userId":"01809937866176487479"}},"outputId":"e374d5e0-7fc6-4774-e478-339325bd01eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1 1 0 ... 0 1 0]\n"]}]},{"cell_type":"code","source":["# Calculate misclassification error\n","predictions = model.predict(x_test)\n","predicted_labels = np.argmax(predictions, axis=1)\n","true_labels = np.argmax(y_test, axis=1)\n","misclassified_indices = np.where(predicted_labels != true_labels)[0]\n","print(\"Misclassified indices:\", misclassified_indices)\n","misclassified_samples = x_test[misclassified_indices]\n","#print(misclassified_samples)\n","misclassification_error = np.sum(predicted_labels != true_labels) / len(true_labels)\n","print(\"Misclassification error: \", misclassification_error)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D8DPg4ZI9xLj","executionInfo":{"status":"ok","timestamp":1714707861766,"user_tz":240,"elapsed":1099,"user":{"displayName":"Vamsi Manda","userId":"01809937866176487479"}},"outputId":"4ef6977d-1062-428d-eeb4-b5cbc6d5ebb7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["80/80 [==============================] - 0s 5ms/step\n","Misclassified indices: [  34   36   42   60   66   78   92   93   94   97   98  111  112  115\n","  130  135  136  150  162  164  166  172  174  177  178  193  195  196\n","  199  214  222  224  245  247  251  266  267  275  277  278  279  299\n","  315  316  322  349  362  364  410  419  424  433  435  436  440  469\n","  486  487  488  496  497  499  509  524  526  551  553  555  556  563\n","  565  567  572  587  593  599  602  606  608  609  614  652  667  677\n","  679  680  683  686  696  706  707  713  730  732  756  770  772  774\n","  775  776  799  800  811  824  828  832  833  834  837  840  843  848\n","  854  859  867  868  881  892  896  904  906  909  923  925  958  959\n","  963  967  973  978  985 1009 1011 1012 1015 1017 1022 1030 1039 1049\n"," 1051 1054 1055 1057 1058 1069 1072 1075 1097 1098 1102 1106 1107 1108\n"," 1111 1114 1116 1119 1122 1124 1127 1130 1151 1156 1164 1165 1174 1182\n"," 1185 1188 1191 1195 1202 1205 1209 1214 1224 1225 1231 1238 1247 1254\n"," 1261 1269 1272 1274 1281 1283 1286 1294 1299 1330 1336 1337 1339 1341\n"," 1345 1355 1372 1377 1390 1417 1423 1464 1465 1467 1469 1471 1476 1478\n"," 1489 1493 1500 1505 1518 1524 1537 1539 1543 1549 1572 1577 1581 1582\n"," 1600 1621 1644 1649 1651 1652 1655 1666 1675 1678 1685 1688 1697 1699\n"," 1703 1717 1734 1735 1737 1742 1746 1747 1750 1759 1765 1766 1767 1772\n"," 1773 1775 1781 1791 1805 1817 1830 1838 1847 1850 1851 1853 1860 1868\n"," 1877 1888 1903 1906 1912 1914 1915 1916 1917 1926 1929 1930 1931 1949\n"," 1954 1962 1964 1967 1972 1977 1981 1983 1987 2000 2001 2006 2007 2012\n"," 2031 2038 2041 2048 2056 2067 2072 2078 2099 2107 2108 2114 2118 2119\n"," 2123 2127 2148 2149 2153 2157 2159 2164 2179 2187 2191 2194 2195 2196\n"," 2205 2211 2222 2235 2253 2263 2264 2265 2280 2281 2284 2285 2288 2296\n"," 2303 2328 2329 2330 2341 2344 2346 2361 2365 2369 2373 2375 2384 2406\n"," 2408 2411 2414 2448 2449 2455 2466 2476 2477 2481 2491 2494 2496 2499\n"," 2501 2517 2519 2521 2522 2527 2528 2532 2544 2549]\n","Misclassification error:  0.1462079749804535\n"]}]},{"cell_type":"code","source":[" import os\n","import csv\n","import sys\n","import math\n","import cv2\n","import scipy\n","import pickle\n","import librosa\n","import matplotlib\n","import numpy as np\n","import librosa.display\n","import IPython.display as ipd\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import keras\n","from keras import layers\n","from keras import models\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D,Conv1D, Flatten,Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.layers import LSTM\n","from keras.layers import Dense\n","from keras.optimizers import Adam\n","from keras.models import load_model\n","from sklearn.metrics import confusion_matrix\n","from sklearn.utils.multiclass import unique_labels\n","import seaborn as sn\n","import random\n","\n","prog = []\n","nonprog = []\n","total_files = 0\n","total_prog = 0\n","total_non_prog = 0\n","\n","# find total files\n","# for root, dirs, files in os.walk(\"/content/drive/MyDrive/Music-Genre-Classification-master-20240427T160246Z-001/Music-Genre-Classification-master/Test_set/Progressive Rock Songs\", topdown=False):\n","#    for name in files:\n","#       filename = os.path.join(root, name)\n","#       if filename.find(\".mp3\") != -1 or filename.find(\".wav\") != -1 or filename.find(\".flac\") != -1 or filename.find(\".avi\") != -1 or filename.find(\".m4a\") != -1 or filename.find(\".ogg\") != -1 :\n","#           total_files = total_files + 1\n","#           total_prog += 1\n","\n","# for root, dirs, files in os.walk(\"/content/drive/MyDrive/Music-Genre-Classification-master-20240427T160246Z-001/Music-Genre-Classification-master/Test_set/Not_Progressive_Rock\", topdown=False):\n","#    for name in files:\n","#       filename = os.path.join(root, name)\n","#       if filename.find(\".mp3\") != -1 or filename.find(\".wav\") != -1 or filename.find(\".flac\") != -1 or filename.find(\".avi\") != -1 or filename.find(\".m4a\") != -1 or filename.find(\".ogg\") != -1 :\n","#           total_files = total_files + 1\n","#           total_non_prog += 1\n","\n","for root, dirs, files in os.walk(\"/content/drive/MyDrive/Music-Genre-Classification-master-20240427T160246Z-001/Music-Genre-Classification-master/Test_set/Other\", topdown=False):\n","   for name in files:\n","      filename = os.path.join(root, name)\n","      if filename.find(\".mp3\") != -1 or filename.find(\".wav\") != -1 or filename.find(\".flac\") != -1 or filename.find(\".avi\") != -1 or filename.find(\".m4a\") != -1 or filename.find(\".ogg\") != -1 :\n","          total_files = total_files + 1\n","          total_prog += 1\n","\n","\n","# --------Extract data from csv file--------------------------------------\n","\n","data = pd.read_csv('/content/drive/MyDrive/Music-Genre-Classification-master-20240427T160246Z-001/Music-Genre-Classification-master/test_djent_features.csv')\n","data.head()\n","new_files = data['filename']\n","new_files = list(new_files)\n","for i in range(len(new_files)) :\n","    new_files[i] = (new_files[i].split(\"chunk\") )[0]\n","\n","\n","data = data.drop(['filename'],axis=1)\n","data = np.asarray(data)\n","\n","X = data[:,6:]\n","y = data[:,0]\n","y[y==\"djent\"] = 0\n","\n","\n","X = np.reshape(X, (X.shape[0],1, X.shape[1]))\n","X = X.astype(np.float32)\n","print(\"X_train shape \",X.shape)\n","y_test = y\n","y_test = to_categorical(y_test)\n","\n","\n","model = load_model('Model.h5')\n","\n","print(\"\\nTesting ...\")\n","\n","# Predict using saved model\n","\n","predictions = model.predict(X)\n","print(predictions)\n","row,col = predictions.shape\n","count = 0\n","for i in range(row) :\n","    true_val = np.argmax(y_test[i])\n","    predicted_val = np.argmax(predictions[i])\n","    # print(\"true \",true_val,\"    got \",predicted_val)\n","    if true_val == predicted_val :\n","       count += 1\n","print(\"Acc \",count,\" / \",row)\n","print(\"Total files \",total_files)\n","\n","\n","new_true_ind = []\n","new_predicted_ind = []\n","i = 0\n","\n","ind = []\n","start = 0\n","for i in range(len(new_files)) :\n","    if i == 0 :\n","        start = 0\n","    elif i == len(new_files) - 1 :\n","        if new_files[i] == new_files[i-1] :\n","            ind.append([new_files[i],start,len(new_files)-1])\n","        else :\n","            ind.append([new_files[i],len(new_files)-1,len(new_files)-1])\n","\n","    else :\n","         if new_files[i] != new_files[i-1] :\n","             end = i-1\n","             ind.append([new_files[i-1],start,end])\n","             start = i\n","\n","print(\"indices calculated\")\n","\n","for i in range(row) :\n","    new_predicted_ind.append(np.argmax(predictions[i]))\n","    new_true_ind.append(np.argmax(y_test[i]))\n","\n","# Find majority result for song chunks\n","\n","# def calc_majority(indices,predicted,true) :\n","#     name = indices[0]\n","#     start = indices[1]\n","#     end = indices[2]\n","#     new_predicted = predicted[start:end+1]\n","#     new_true = true[start:end+1]\n","#     maj_pred = 0\n","#     maj_true = 0\n","#     for i in range(len(new_predicted)) :\n","#         if new_predicted[i] == 0 :\n","#             maj_pred += 1\n","#     if maj_pred <= 2*len(new_predicted)/3  :\n","#        ret_pred_val = 1\n","#     else:\n","#         ret_pred_val=0\n","\n","#     if name.find(\"nonprog\") != -1 :\n","#         ret_true_val = 1\n","#     else :\n","#         ret_true_val = 0\n","#     return [ret_pred_val,ret_true_val]\n","\n","def calc_majority(indices, predicted, true):\n","    name = indices[0]\n","    start = indices[1]\n","    end = indices[2]\n","    new_predicted = predicted[start:end+1]\n","    new_true = true[start:end+1]\n","    maj_pred = 0\n","    for pred in new_predicted:\n","        if pred == 0:\n","            maj_pred += 1\n","    ret_pred_val = 0 if maj_pred > len(new_predicted)/2 else 1\n","\n","    ret_true_val = 1 if name.find(\"nonprog\") != -1 else 0\n","    return name, ret_pred_val, ret_true_val  # Return name as well\n","\n","\n","\n","majority_pred = []\n","majority_true = []\n","\n","print(\"len ind\",len(ind))\n","\n","# Find accuracy for all chunks by checking majority output\n","failed_predictions = []\n","\n","for i in range(len(ind)):\n","    name, ret_pred_val, ret_true_val = calc_majority(ind[i], new_predicted_ind, new_true_ind)\n","    majority_pred.append(ret_pred_val)\n","    majority_true.append(ret_true_val)\n","    if ret_pred_val != ret_true_val:\n","        failed_predictions.append((name, ret_true_val, ret_pred_val))\n","\n","count = 0\n","print(\"len maj\",len(majority_pred))\n","for i in range(len(majority_pred)) :\n","    #print(\"true \",majority_true[i],\"     predicted\",majority_pred[i])\n","    if majority_pred[i] == majority_true[i] :\n","        count += 1\n","# Assuming majority_true and majority_pred are lists of equal length\n","assert len(majority_true) == len(majority_pred)\n","\n","\n","# Open a new file to write the data\n","with open('majority_predictions.csv', 'w', newline='') as csvfile:\n","    writer = csv.writer(csvfile)\n","    writer.writerow(['Song Name', 'True', 'Predicted'])  # Adjust header to include song names\n","\n","    # Write only failed predictions\n","    for item in failed_predictions:\n","        writer.writerow(item)  # Write each entry\n","\n","\n","\n","\n","\n","print(\"Accuracy \",count,\" / \",total_files, (count/total_files) *100,\" %\" )\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UHDtheFe796A","executionInfo":{"status":"ok","timestamp":1714716678452,"user_tz":240,"elapsed":2125,"user":{"displayName":"Vamsi Manda","userId":"01809937866176487479"}},"outputId":"4e443ad8-bf4b-4845-c46f-69930bd98bcb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X_train shape  (204, 1, 21)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Testing ...\n","7/7 [==============================] - 1s 5ms/step\n","[[0.30809194 0.7988365 ]\n"," [0.07577261 0.9732224 ]\n"," [0.09193101 0.96643186]\n"," [0.03911426 0.98762184]\n"," [0.18380757 0.9061602 ]\n"," [0.2370923  0.8681174 ]\n"," [0.20045313 0.89843   ]\n"," [0.19328569 0.89832085]\n"," [0.00650749 0.998637  ]\n"," [0.00768399 0.9984982 ]\n"," [0.01018575 0.99776155]\n"," [0.00863327 0.9981464 ]\n"," [0.00885446 0.99817276]\n"," [0.01037316 0.9977052 ]\n"," [0.0082312  0.99836427]\n"," [0.00885058 0.99820304]\n"," [0.01488311 0.99657995]\n"," [0.01069165 0.9975984 ]\n"," [0.00275306 0.9995107 ]\n"," [0.00146106 0.99978167]\n"," [0.00172097 0.99974334]\n"," [0.0012258  0.99982893]\n"," [0.00140402 0.9997861 ]\n"," [0.00137119 0.99980557]\n"," [0.00279197 0.9995219 ]\n"," [0.00264166 0.9995742 ]\n"," [0.00266631 0.9995678 ]\n"," [0.0036607  0.9994494 ]\n"," [0.00314038 0.9994379 ]\n"," [0.37107325 0.62925255]\n"," [0.24418847 0.79746723]\n"," [0.191458   0.83901066]\n"," [0.15997504 0.8764749 ]\n"," [0.12886089 0.90917647]\n"," [0.20800757 0.82284236]\n"," [0.22725032 0.8112729 ]\n"," [0.41001076 0.5804669 ]\n"," [0.18534485 0.8515131 ]\n"," [0.21261957 0.8276229 ]\n"," [0.43778238 0.5376213 ]\n"," [0.10195912 0.93187857]\n"," [0.08721656 0.96122605]\n"," [0.19333646 0.88800544]\n"," [0.10068883 0.9517509 ]\n"," [0.07113852 0.97260755]\n"," [0.08744389 0.96025777]\n"," [0.7510827  0.21822615]\n"," [0.31137505 0.8266294 ]\n"," [0.36249274 0.6990124 ]\n"," [0.17855036 0.8878625 ]\n"," [0.06231657 0.965309  ]\n"," [0.37689054 0.6730171 ]\n"," [0.20692763 0.87043554]\n"," [0.26232746 0.8201656 ]\n"," [0.12456614 0.9400461 ]\n"," [0.764746   0.2118062 ]\n"," [0.03842904 0.9848429 ]\n"," [0.09467891 0.94441223]\n"," [0.21590514 0.8339473 ]\n"," [0.15122683 0.9238841 ]\n"," [0.8554793  0.084146  ]\n"," [0.27510524 0.730228  ]\n"," [0.28083244 0.776385  ]\n"," [0.20654401 0.8635811 ]\n"," [0.06047921 0.9744195 ]\n"," [0.4036349  0.59989077]\n"," [0.13812228 0.9165541 ]\n"," [0.24504697 0.82571095]\n"," [0.08035214 0.95732695]\n"," [0.25446236 0.7891859 ]\n"," [0.1344977  0.91850203]\n"," [0.07008249 0.9761707 ]\n"," [0.24353905 0.8542519 ]\n"," [0.44931927 0.60999304]\n"," [0.69232446 0.31109968]\n"," [0.23118356 0.8651737 ]\n"," [0.17605588 0.9095414 ]\n"," [0.5191758  0.5517808 ]\n"," [0.43375015 0.651608  ]\n"," [0.03112706 0.9916052 ]\n"," [0.09342922 0.95636463]\n"," [0.27414727 0.80631185]\n"," [0.0153608  0.9957287 ]\n"," [0.31696045 0.7735724 ]\n"," [0.13514756 0.9329004 ]\n"," [0.03937175 0.9857286 ]\n"," [0.03396786 0.9807313 ]\n"," [0.01263647 0.99437076]\n"," [0.52438474 0.46532688]\n"," [0.00437638 0.9992204 ]\n"," [0.00430906 0.9992017 ]\n"," [0.00443287 0.999182  ]\n"," [0.01097545 0.997392  ]\n"," [0.0047972  0.99913025]\n"," [0.01183001 0.99714845]\n"," [0.01638826 0.9936297 ]\n"," [0.05483358 0.9752671 ]\n"," [0.00970937 0.9968102 ]\n"," [0.1150738  0.9361078 ]\n"," [0.04007597 0.98375183]\n"," [0.01833841 0.9939283 ]\n"," [0.03125879 0.98759586]\n"," [0.01298489 0.99679935]\n"," [0.20207962 0.86358356]\n"," [0.10774427 0.9597752 ]\n"," [0.2630969  0.83682525]\n"," [0.16473351 0.9118031 ]\n"," [0.06687215 0.9761064 ]\n"," [0.02026426 0.9946974 ]\n"," [0.062858   0.9752145 ]\n"," [0.02178965 0.9945167 ]\n"," [0.02857429 0.9915277 ]\n"," [0.06181344 0.9735411 ]\n"," [0.0232594  0.9933974 ]\n"," [0.02794049 0.9912461 ]\n"," [0.04766001 0.98266244]\n"," [0.00945227 0.9979376 ]\n"," [0.03096556 0.99121577]\n"," [0.31565762 0.7554755 ]\n"," [0.6359998  0.37890673]\n"," [0.24699628 0.83496726]\n"," [0.38891032 0.6266937 ]\n"," [0.5015503  0.50138557]\n"," [0.71024716 0.2853704 ]\n"," [0.8804183  0.08912084]\n"," [0.6667549  0.3296326 ]\n"," [0.4186356  0.63869303]\n"," [0.6742139  0.28206372]\n"," [0.21685725 0.8361238 ]\n"," [0.25664678 0.7947181 ]\n"," [0.2806968  0.75504005]\n"," [0.3340554  0.7143546 ]\n"," [0.1533267  0.9137003 ]\n"," [0.10264102 0.9480825 ]\n"," [0.06776074 0.97531855]\n"," [0.10296384 0.95415604]\n"," [0.22537005 0.8394574 ]\n"," [0.04111963 0.98570013]\n"," [0.35610524 0.70308554]\n"," [0.0498809  0.9801472 ]\n"," [0.08775336 0.95484775]\n"," [0.05763422 0.97922385]\n"," [0.5600579  0.41779122]\n"," [0.5139147  0.52426654]\n"," [0.07332288 0.9650749 ]\n"," [0.07528702 0.95569   ]\n"," [0.25383833 0.8342052 ]\n"," [0.28011015 0.8223174 ]\n"," [0.1849962  0.89077115]\n"," [0.20971943 0.86736083]\n"," [0.22241884 0.8726745 ]\n"," [0.14354046 0.8843157 ]\n"," [0.06570141 0.963739  ]\n"," [0.51703054 0.51846313]\n"," [0.4650731  0.5903182 ]\n"," [0.24563777 0.8431045 ]\n"," [0.50507224 0.54200965]\n"," [0.40159932 0.6884929 ]\n"," [0.21585698 0.86642057]\n"," [0.49243656 0.56793964]\n"," [0.51850104 0.53536266]\n"," [0.11993495 0.92670846]\n"," [0.23431432 0.8162605 ]\n"," [0.313479   0.73015374]\n"," [0.11987369 0.9405694 ]\n"," [0.10970671 0.94343936]\n"," [0.13947968 0.9197275 ]\n"," [0.5114147  0.48894316]\n"," [0.2103207  0.8421629 ]\n"," [0.01635807 0.9946083 ]\n"," [0.00706066 0.9978971 ]\n"," [0.03468391 0.98652995]\n"," [0.01657688 0.9944423 ]\n"," [0.10176694 0.953489  ]\n"," [0.01735658 0.9938946 ]\n"," [0.01422207 0.9950206 ]\n"," [0.02443314 0.98984563]\n"," [0.03703089 0.9833421 ]\n"," [0.13980314 0.912866  ]\n"," [0.17611277 0.9053764 ]\n"," [0.03317254 0.9848084 ]\n"," [0.0674661  0.9761369 ]\n"," [0.07755372 0.96362084]\n"," [0.08102471 0.96614337]\n"," [0.08943707 0.9637668 ]\n"," [0.0484762  0.9865092 ]\n"," [0.08026607 0.9634998 ]\n"," [0.08481713 0.96548605]\n"," [0.4490889  0.52478844]\n"," [0.14256692 0.8807839 ]\n"," [0.75292283 0.20650676]\n"," [0.58441347 0.37536573]\n"," [0.75523007 0.16496995]\n"," [0.7870429  0.1270972 ]\n"," [0.80421734 0.12732837]\n"," [0.03181029 0.98508424]\n"," [0.12016125 0.92268914]\n"," [0.41411325 0.57474595]\n"," [0.39285198 0.61525154]\n"," [0.2838379  0.7603238 ]\n"," [0.63582665 0.30133912]\n"," [0.7970858  0.14223737]\n"," [0.23382686 0.80832833]\n"," [0.47148868 0.50025696]]\n","Acc  20  /  204\n","Total files  22\n","indices calculated\n","len ind 22\n","len maj 22\n","Accuracy  0  /  22 0.0  %\n"]}]},{"cell_type":"code","source":["majority_pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lJSxDmw5GJ2H","executionInfo":{"status":"ok","timestamp":1714716981700,"user_tz":240,"elapsed":332,"user":{"displayName":"Vamsi Manda","userId":"01809937866176487479"}},"outputId":"ee1d812e-4a7c-4568-ee48-7692c3baed33"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["import sys\n","import numpy\n","\n","numpy.set_printoptions(threshold=sys.maxsize)\n","print(predicted_val)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38zZfhTvFRNe","executionInfo":{"status":"ok","timestamp":1714716913275,"user_tz":240,"elapsed":173,"user":{"displayName":"Vamsi Manda","userId":"01809937866176487479"}},"outputId":"163bd80a-f037-4254-fd00-9382816cdb29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n"]}]},{"cell_type":"code","source":["misclassification_count = 0\n","\n","# Find misclassification count\n","for true_val, pred_val in zip(majority_true, majority_pred):\n","    if true_val != pred_val:\n","        misclassification_count += 1\n","\n","# Calculate misclassification error\n","misclassification_error = misclassification_count / total_files\n","\n","print(\"Misclassification Error: {} / {} ({:.2%})\".format(misclassification_count, total_files, misclassification_error))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6vJLB8EWkbtF","executionInfo":{"status":"ok","timestamp":1714715917682,"user_tz":240,"elapsed":222,"user":{"displayName":"Vamsi Manda","userId":"01809937866176487479"}},"outputId":"50699f2d-1fb2-47dd-baae-c26324b07044"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Misclassification Error: 79 / 266 (29.70%)\n"]}]},{"cell_type":"code","source":["majority_true"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e3S-rcIPouHk","executionInfo":{"status":"ok","timestamp":1714715727819,"user_tz":240,"elapsed":187,"user":{"displayName":"Vamsi Manda","userId":"01809937866176487479"}},"outputId":"e38f19a1-41c1-4a96-941e-6c0cbed53382"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1]"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["majority_pred"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0F5we9dApPio","executionInfo":{"status":"ok","timestamp":1714715790764,"user_tz":240,"elapsed":325,"user":{"displayName":"Vamsi Manda","userId":"01809937866176487479"}},"outputId":"92aea951-d8a7-4c04-de90-75bdd3342aaf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 0,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 0,\n"," 1,\n"," 0,\n"," 0,\n"," 1]"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","# Calculate confusion matrix\n","confusion_matrix = confusion_matrix(majority_true, majority_pred)\n","# Define class labels for better visualization\n","class_names = [\"Prog\", \"Non-Prog\"]\n","\n","# Create DataFrame for confusion matrix\n","df_cm = pd.DataFrame(confusion_matrix, index=class_names, columns=class_names)\n","\n","# Plot confusion matrix using seaborn heatmap\n","plt.figure(figsize=(10, 7))\n","sn.heatmap(df_cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n","           annot_kws={\"size\": 16}, linewidths=0.5, linecolor='black')\n","\n","# Customize plot\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted Label')\n","plt.ylabel('True Label')\n","plt.xticks(np.arange(len(class_names)) + 0.5, class_names, rotation=45)\n","plt.yticks(np.arange(len(class_names)) + 0.5, class_names, rotation=0)\n","\n","# Display plot\n","plt.tight_layout()\n","display(plt.show())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"9xFyz6d7HTCN","executionInfo":{"status":"ok","timestamp":1714709128857,"user_tz":240,"elapsed":392,"user":{"displayName":"Vamsi Manda","userId":"01809937866176487479"}},"outputId":"db94f65c-1c40-4177-aa31-827edeec8c25"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["None"]},"metadata":{}}]},{"cell_type":"code","source":["confusion_matrix = confusion_matrix(majority_true, majority_pred )\n","print(len(majority_true),\" \",len(majority_pred))\n","df_cm = pd.DataFrame(confusion_matrix, index = [i for i in [\"True prog songs\",\"True nonprog songs\"]],\n","                  columns = [i for i in [\"Predicted prog songs\",\"Predicted nonprog songs\"]])\n","plt.figure(figsize = (10,7))\n","sn.heatmap(df_cm, annot=True)\n","plt.title('Total prog = %i, Total nonprog = %i' %(total_prog,total_non_prog) )\n","df_cm.plot()\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"B6zAOS8TPJJY","executionInfo":{"status":"error","timestamp":1714709131740,"user_tz":240,"elapsed":192,"user":{"displayName":"Vamsi Manda","userId":"01809937866176487479"}},"outputId":"e263f486-33dc-4e6f-a66f-0f694c7d7fc3"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"'numpy.ndarray' object is not callable","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-a5c3650b745e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajority_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajority_pred\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajority_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajority_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m df_cm = pd.DataFrame(confusion_matrix, index = [i for i in [\"True prog songs\",\"True nonprog songs\"]],\n\u001b[1;32m      4\u001b[0m                   columns = [i for i in [\"Predicted prog songs\",\"Predicted nonprog songs\"]])\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sn\n","import pandas as pd\n","\n","# Assuming you have defined confusion_matrix, majority_true, majority_pred, total_prog, and total_non_prog correctly\n","\n","# Check if confusion_matrix is a function or variable\n","# If it's a variable, ensure it contains the confusion matrix data\n","# If it's a function, make sure it's properly defined and called\n","print(\"Shape of confusion matrix:\", confusion_matrix.shape)\n","\n","# Check if total_prog and total_non_prog are defined and have correct values\n","print(\"Total prog:\", total_prog)\n","print(\"Total nonprog:\", total_non_prog)\n","\n","# Create DataFrame for confusion matrix\n","df_cm = pd.DataFrame(confusion_matrix, index=[\"True prog songs\", \"True nonprog songs\"],\n","                     columns=[\"Predicted prog songs\", \"Predicted nonprog songs\"])\n","\n","# Create heatmap\n","plt.figure(figsize=(10, 7))\n","sn.heatmap(df_cm, cmap=plt.cm.Blues)\n","plt.title('Total prog = %i, Total nonprog = %i' % (total_prog, total_non_prog))\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xOJvUXHfSytK","executionInfo":{"status":"ok","timestamp":1714709133619,"user_tz":240,"elapsed":468,"user":{"displayName":"Vamsi Manda","userId":"01809937866176487479"}},"outputId":"653f3a7d-a444-4a69-f6fb-9d93955d23e0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of confusion matrix: (2, 2)\n","Total prog: 136\n","Total nonprog: 130\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"bkXLcCsyUpSu"},"execution_count":null,"outputs":[]}]}